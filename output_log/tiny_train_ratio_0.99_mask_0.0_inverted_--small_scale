Wed Aug 14 20:09:27 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 4090        On  |   00000000:00:08.0 Off |                  Off |
| 30%   33C    P8             17W /  450W |       1MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
/cluster/customapps/biomed/vogtlab/abizeul/software/anaconda/envs/reconstruction/lib/python3.12/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Sum of mask tensor(0., device='cuda:0')
Started eval
/cluster/customapps/biomed/vogtlab/abizeul/software/anaconda/envs/reconstruction/lib/python3.12/site-packages/torch/utils/data/dataloader.py:557: UserWarning:

This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.

---- Eval Epoch 10/100
/cluster/customapps/biomed/vogtlab/abizeul/software/anaconda/envs/reconstruction/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:232: UserWarning:

The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.

---- Eval Epoch 20/100
---- Eval Epoch 30/100
---- Eval Epoch 40/100
---- Eval Epoch 50/100
---- Eval Epoch 60/100
---- Eval Epoch 70/100
---- Eval Epoch 80/100
---- Eval Epoch 90/100
---- Eval Epoch 100/100
---- Epoch 9/600 in 126.87s with 0.0 loss
---- Epoch 19/600 in 131.07s with 0.0 loss
---- Epoch 29/600 in 120.16s with 0.0 loss
---- Epoch 39/600 in 125.49s with 0.0 loss
---- Epoch 49/600 in 127.26s with 0.0 loss
---- Epoch 59/600 in 124.29s with 0.0 loss
---- Epoch 69/600 in 120.76s with 0.0 loss
---- Epoch 79/600 in 126.44s with 0.0 loss
---- Epoch 89/600 in 124.13s with 0.0 loss
---- Epoch 99/600 in 105.52s with 0.0 loss
Started eval
---- Eval Epoch 10/100
---- Eval Epoch 20/100
---- Eval Epoch 30/100
---- Eval Epoch 40/100
---- Eval Epoch 50/100
---- Eval Epoch 60/100
---- Eval Epoch 70/100
---- Eval Epoch 80/100
---- Eval Epoch 90/100
---- Eval Epoch 100/100
---- Epoch 109/600 in 111.81s with 0.0 loss
---- Epoch 119/600 in 123.4s with 0.0 loss
---- Epoch 129/600 in 125.32s with 0.0 loss
---- Epoch 139/600 in 124.91s with 0.0 loss
---- Epoch 149/600 in 122.58s with 0.0 loss
---- Epoch 159/600 in 132.73s with 0.0 loss
---- Epoch 169/600 in 131.01s with 0.0 loss
---- Epoch 179/600 in 123.89s with 0.0 loss
---- Epoch 189/600 in 124.25s with 0.0 loss
---- Epoch 199/600 in 127.55s with 0.0 loss
Started eval
---- Eval Epoch 10/100
---- Eval Epoch 20/100
---- Eval Epoch 30/100
---- Eval Epoch 40/100
---- Eval Epoch 50/100
---- Eval Epoch 60/100
---- Eval Epoch 70/100
---- Eval Epoch 80/100
---- Eval Epoch 90/100
---- Eval Epoch 100/100
---- Epoch 209/600 in 122.32s with 0.0 loss
---- Epoch 219/600 in 123.82s with 0.0 loss
---- Epoch 229/600 in 127.81s with 0.0 loss
---- Epoch 239/600 in 126.23s with 0.0 loss
---- Epoch 249/600 in 125.19s with 0.0 loss
---- Epoch 259/600 in 121.76s with 0.0 loss
---- Epoch 269/600 in 120.17s with 0.0 loss
---- Epoch 279/600 in 124.5s with 0.0 loss
---- Epoch 289/600 in 126.16s with 0.0 loss
---- Epoch 299/600 in 129.15s with 0.0 loss
Started eval
---- Eval Epoch 10/100
---- Eval Epoch 20/100
---- Eval Epoch 30/100
---- Eval Epoch 40/100
---- Eval Epoch 50/100
---- Eval Epoch 60/100
---- Eval Epoch 70/100
---- Eval Epoch 80/100
---- Eval Epoch 90/100
---- Eval Epoch 100/100
---- Epoch 309/600 in 125.84s with 0.0 loss
---- Epoch 319/600 in 134.97s with 0.0 loss
---- Epoch 329/600 in 111.35s with 0.0 loss
---- Epoch 339/600 in 135.71s with 0.0 loss
---- Epoch 349/600 in 134.02s with 0.0 loss
---- Epoch 359/600 in 127.52s with 0.0 loss
---- Epoch 369/600 in 133.02s with 0.0 loss
---- Epoch 379/600 in 132.69s with 0.0 loss
---- Epoch 389/600 in 137.21s with 0.0 loss
---- Epoch 399/600 in 133.12s with 0.0 loss
Started eval
---- Eval Epoch 10/100
---- Eval Epoch 20/100
---- Eval Epoch 30/100
---- Eval Epoch 40/100
---- Eval Epoch 50/100
---- Eval Epoch 60/100
---- Eval Epoch 70/100
---- Eval Epoch 80/100
---- Eval Epoch 90/100
---- Eval Epoch 100/100
---- Epoch 409/600 in 124.94s with 0.0 loss
---- Epoch 419/600 in 131.16s with 0.0 loss
---- Epoch 429/600 in 125.07s with 0.0 loss
---- Epoch 439/600 in 115.48s with 0.0 loss
---- Epoch 449/600 in 128.21s with 0.0 loss
---- Epoch 459/600 in 136.19s with 0.0 loss
---- Epoch 469/600 in 125.55s with 0.0 loss
---- Epoch 479/600 in 121.63s with 0.0 loss
---- Epoch 489/600 in 116.33s with 0.0 loss
---- Epoch 499/600 in 123.57s with 0.0 loss
Started eval
---- Eval Epoch 10/100
---- Eval Epoch 20/100
---- Eval Epoch 30/100
---- Eval Epoch 40/100
---- Eval Epoch 50/100
---- Eval Epoch 60/100
---- Eval Epoch 70/100
---- Eval Epoch 80/100
---- Eval Epoch 90/100
---- Eval Epoch 100/100
---- Epoch 509/600 in 131.79s with 0.0 loss
---- Epoch 519/600 in 126.89s with 0.0 loss
---- Epoch 529/600 in 121.1s with 0.0 loss
---- Epoch 539/600 in 139.73s with 0.0 loss
---- Epoch 549/600 in 121.53s with 0.0 loss
---- Epoch 559/600 in 124.5s with 0.0 loss
---- Epoch 569/600 in 127.69s with 0.0 loss
---- Epoch 579/600 in 126.05s with 0.0 loss
---- Epoch 589/600 in 116.82s with 0.0 loss
---- Epoch 599/600 in 121.29s with 0.0 loss
Started eval
---- Eval Epoch 10/100
---- Eval Epoch 20/100
---- Eval Epoch 30/100
---- Eval Epoch 40/100
---- Eval Epoch 50/100
---- Eval Epoch 60/100
---- Eval Epoch 70/100
---- Eval Epoch 80/100
---- Eval Epoch 90/100
---- Eval Epoch 100/100
---- OG Eval Epoch 10/100
---- OG Eval Epoch 20/100
---- OG Eval Epoch 30/100
---- OG Eval Epoch 40/100
---- OG Eval Epoch 50/100
---- OG Eval Epoch 60/100
---- OG Eval Epoch 70/100
---- OG Eval Epoch 80/100
---- OG Eval Epoch 90/100
---- OG Eval Epoch 100/100
