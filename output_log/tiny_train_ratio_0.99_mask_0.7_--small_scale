Fri Aug 16 01:26:48 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 4090        On  |   00000000:00:0B.0 Off |                  Off |
| 30%   37C    P8             16W /  450W |       1MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
/cluster/customapps/biomed/vogtlab/abizeul/software/anaconda/envs/reconstruction/lib/python3.12/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Sum of mask tensor(4423680., device='cuda:0')
Started eval
/cluster/customapps/biomed/vogtlab/abizeul/software/anaconda/envs/reconstruction/lib/python3.12/site-packages/torch/utils/data/dataloader.py:557: UserWarning:

This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.

---- Eval Epoch 10/100
/cluster/customapps/biomed/vogtlab/abizeul/software/anaconda/envs/reconstruction/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:232: UserWarning:

The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.

---- Eval Epoch 20/100
---- Eval Epoch 30/100
---- Eval Epoch 40/100
---- Eval Epoch 50/100
---- Eval Epoch 60/100
---- Eval Epoch 70/100
---- Eval Epoch 80/100
---- Eval Epoch 90/100
---- Eval Epoch 100/100
---- Epoch 9/600 in 126.95s with 0.11 loss
---- Epoch 19/600 in 116.53s with 0.11 loss
---- Epoch 29/600 in 125.82s with 0.11 loss
---- Epoch 39/600 in 111.06s with 0.11 loss
---- Epoch 49/600 in 112.97s with 0.11 loss
---- Epoch 59/600 in 123.81s with 0.11 loss
---- Epoch 69/600 in 122.66s with 0.11 loss
---- Epoch 79/600 in 113.88s with 0.11 loss
---- Epoch 89/600 in 132.65s with 0.11 loss
---- Epoch 99/600 in 138.57s with 0.11 loss
Started eval
---- Eval Epoch 10/100
---- Eval Epoch 20/100
---- Eval Epoch 30/100
---- Eval Epoch 40/100
---- Eval Epoch 50/100
---- Eval Epoch 60/100
---- Eval Epoch 70/100
---- Eval Epoch 80/100
---- Eval Epoch 90/100
---- Eval Epoch 100/100
---- Epoch 109/600 in 126.14s with 0.11 loss
---- Epoch 119/600 in 136.45s with 0.11 loss
---- Epoch 129/600 in 129.45s with 0.11 loss
---- Epoch 139/600 in 125.89s with 0.11 loss
---- Epoch 149/600 in 132.79s with 0.11 loss
---- Epoch 159/600 in 128.79s with 0.11 loss
---- Epoch 169/600 in 118.64s with 0.11 loss
---- Epoch 179/600 in 138.83s with 0.11 loss
---- Epoch 189/600 in 137.87s with 0.11 loss
---- Epoch 199/600 in 118.25s with 0.11 loss
Started eval
---- Eval Epoch 10/100
---- Eval Epoch 20/100
---- Eval Epoch 30/100
---- Eval Epoch 40/100
---- Eval Epoch 50/100
---- Eval Epoch 60/100
---- Eval Epoch 70/100
---- Eval Epoch 80/100
---- Eval Epoch 90/100
---- Eval Epoch 100/100
---- Epoch 209/600 in 121.31s with 0.11 loss
---- Epoch 219/600 in 124.98s with 0.11 loss
---- Epoch 229/600 in 124.87s with 0.11 loss
---- Epoch 239/600 in 130.95s with 0.11 loss
---- Epoch 249/600 in 138.73s with 0.11 loss
---- Epoch 259/600 in 139.24s with 0.11 loss
---- Epoch 269/600 in 121.01s with 0.11 loss
---- Epoch 279/600 in 139.13s with 0.11 loss
---- Epoch 289/600 in 125.25s with 0.11 loss
---- Epoch 299/600 in 120.54s with 0.11 loss
Started eval
---- Eval Epoch 10/100
---- Eval Epoch 20/100
---- Eval Epoch 30/100
---- Eval Epoch 40/100
---- Eval Epoch 50/100
---- Eval Epoch 60/100
---- Eval Epoch 70/100
---- Eval Epoch 80/100
---- Eval Epoch 90/100
---- Eval Epoch 100/100
---- Epoch 309/600 in 135.71s with 0.11 loss
---- Epoch 319/600 in 121.13s with 0.11 loss
---- Epoch 329/600 in 130.41s with 0.11 loss
---- Epoch 339/600 in 130.59s with 0.11 loss
---- Epoch 349/600 in 122.15s with 0.11 loss
---- Epoch 359/600 in 132.77s with 0.11 loss
---- Epoch 369/600 in 122.94s with 0.1 loss
---- Epoch 379/600 in 120.9s with 0.1 loss
---- Epoch 389/600 in 138.84s with 0.1 loss
---- Epoch 399/600 in 126.57s with 0.1 loss
Started eval
---- Eval Epoch 10/100
---- Eval Epoch 20/100
---- Eval Epoch 30/100
---- Eval Epoch 40/100
---- Eval Epoch 50/100
---- Eval Epoch 60/100
---- Eval Epoch 70/100
---- Eval Epoch 80/100
---- Eval Epoch 90/100
---- Eval Epoch 100/100
